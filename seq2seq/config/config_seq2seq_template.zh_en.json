{
    "data_src_train_file": "data/cwmt.neu2017.english.chinese/NEU_cn.token.train.txt",
    "data_trg_train_file": "data/cwmt.neu2017.english.chinese/NEU_en.token.train.txt",
    "data_src_eval_file": "data/cwmt.neu2017.english.chinese/NEU_cn.token.dev.txt",
    "data_trg_eval_file": "data/cwmt.neu2017.english.chinese/NEU_en.token.dev.txt",
    "data_src_vocab_file": "data/cwmt.neu2017.english.chinese/NEU_cn.vocab.txt",
    "data_trg_vocab_file": "data/cwmt.neu2017.english.chinese/NEU_en.vocab.txt",
    "data_src_embedding_file": "data/fasttext/cwmt_neu2017.wiki.zh.vec",
    "data_trg_embedding_file": "data/fasttext/cwmt_neu2017.wiki.en.vec",
    "data_src_full_embedding_file": "data/fasttext/wiki.zh.vec",
    "data_trg_full_embedding_file": "data/fasttext/wiki.en.vec",
    "data_src_vocab_size": 30000,
    "data_trg_vocab_size": 30000,
    "data_src_max_length": 50,
    "data_trg_max_length": 50,
    "data_src_reverse": false,
    "data_share_vocab": false,
    "data_log_output_dir": "output/log",
    "data_result_output_dir": "output/result",
    "train_random_seed": 100,
    "train_batch_size": 128,
    "train_eval_batch_size": 256,
    "train_eval_metric": "bleu",
    "train_num_epoch": 10,
    "train_ckpt_output_dir": "output/checkpoint",
    "train_summary_output_dir": "output/summary",
    "train_step_per_stat": 10,
    "train_step_per_ckpt": 100,
    "train_step_per_eval": 100,
    "train_clip_norm": 5.0,
    "train_optimizer_type": "adam",
    "train_optimizer_learning_rate": 0.001,
    "train_optimizer_adam_beta_1": 0.9,
    "train_optimizer_adam_beta_2": 0.999,
    "train_optimizer_adam_epsilon": 1e-08,
    "model_type": "vanilla",
    "model_scope": "seq2seq",
    "model_pretrained_embedding": true,
    "model_encoder_type": "bi",
    "model_encoder_embed_dim": 300,
    "model_encoder_num_layer": 1,
    "model_encoder_unit_dim": 512,
    "model_encoder_unit_type": "lstm",
    "model_encoder_dropout": 0.2,
    "model_decoder_type": "uni",
    "model_decoder_embed_dim": 300,
    "model_decoder_num_layer": 2,
    "model_decoder_unit_dim": 512,
    "model_decoder_unit_type": "lstm",
    "model_decoder_dropout": 0.2,
    "model_decoder_attention_type": "bahdanau",
    "model_decoder_attention_dim": 512,
    "model_decoder_decoding": "greedy",
    "model_decoder_beam_size": 10,
    "device_num_gpus": 1,
    "device_default_gpu_id": 0,
    "device_log_device_placement": false,
    "device_allow_soft_placement": true
}